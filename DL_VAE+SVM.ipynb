{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnOzfv-nuQr7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQXoWvMqXh9l"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbUpJOuqWJUL",
        "outputId": "b91d33c6-2afb-4339-c552-bacff86530e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 7932572.19it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 170071.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:03<00:00, 1421193.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23019485.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Load the FashionMNIST dataset\n",
        "transform = transforms.ToTensor()\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split labeled data evenly across classes\n",
        "def split_labeled_data(dataset, num_labels, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    indices = np.arange(len(dataset))\n",
        "    labels = np.array(dataset.targets)\n",
        "\n",
        "    labeled_indices = []\n",
        "    for i in range(10):  # 10 classes\n",
        "        class_indices = np.where(labels == i)[0]\n",
        "        labeled_indices.extend(np.random.choice(class_indices, num_labels // 10, replace=False))\n",
        "\n",
        "    unlabeled_indices = list(set(indices) - set(labeled_indices))\n",
        "    return labeled_indices, unlabeled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Kf1vLqnrym"
      },
      "outputs": [],
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, input_dim=784, hidden_dim=635, latent_dim=10):\n",
        "        super(VAE, self).__init__()\n",
        "        # Encoder\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3_mu = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.fc3_logvar = nn.Linear(hidden_dim, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.fc4 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.fc5 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc6 = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.softplus(self.fc1(x))  # softplus activation\n",
        "        h2 = F.softplus(self.fc2(h1))  # softplus activation\n",
        "        mu = self.fc3_mu(h2)\n",
        "        logvar = self.fc3_logvar(h2)\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.softplus(self.fc4(z))  # softplus activation\n",
        "        h4 = F.softplus(self.fc5(h3))  # softplus activation\n",
        "        return torch.sigmoid(self.fc6(h4))  # final layer outputs a probability distribution\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)  # flatten the input\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "    def loss_function(self, recon_x, x, mu, logvar):\n",
        "        BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "        return BCE + KLD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QavYN7qts2rl"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlh7e1pqn6sD"
      },
      "outputs": [],
      "source": [
        "def save_vae_weights(vae, num_labels):\n",
        "    # Create a directory to save weights if it doesn't exist\n",
        "    save_dir = '/content/vae_weights'\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    # Save the weights\n",
        "    save_path = os.path.join(save_dir, f'vae_weights_{num_labels}_labels.pth')\n",
        "    torch.save(vae.state_dict(), save_path)\n",
        "    print(f\"VAE weights saved to {save_path}\")\n",
        "\n",
        "def print_data_sizes(num_labels):\n",
        "    labeled_indices, unlabeled_indices = split_labeled_data(train_dataset, num_labels=num_labels)\n",
        "\n",
        "    print(f\"\\nData sizes for {num_labels} labels:\")\n",
        "    print(f\"  Labeled data size: {len(labeled_indices)}\")\n",
        "    print(f\"  Unlabeled data size: {len(unlabeled_indices)}\")\n",
        "    print(f\"  Test data size: {len(test_dataset)}\")\n",
        "    print(f\"  Total training data size: {len(train_dataset)}\")\n",
        "\n",
        "def train_vae(vae, labeled_loader, unlabeled_loader, optimizer, num_labels, num_epochs=500):\n",
        "    vae.train()\n",
        "    for epoch in tqdm(range(num_epochs), desc=f'Training VAE with {num_labels} labels'):\n",
        "        train_loss = 0\n",
        "        for (data, _), (unlabeled_data, _) in zip(labeled_loader, unlabeled_loader):\n",
        "            data = data.to(device)\n",
        "            unlabeled_data = unlabeled_data.to(device)\n",
        "\n",
        "            # Flatten the input\n",
        "            data = data.view(data.size(0), -1)\n",
        "            unlabeled_data = unlabeled_data.view(unlabeled_data.size(0), -1)\n",
        "\n",
        "            # Zero the gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass for labeled data\n",
        "            recon_batch, mu, logvar = vae(data)\n",
        "            loss = vae.loss_function(recon_batch, data, mu, logvar)\n",
        "\n",
        "            # Forward pass for unlabeled data\n",
        "            recon_unlabeled, mu_unlabeled, logvar_unlabeled = vae(unlabeled_data)\n",
        "            loss_unlabeled = vae.loss_function(recon_unlabeled, unlabeled_data, mu_unlabeled, logvar_unlabeled)\n",
        "\n",
        "            # Combine losses (you might consider a weight for the unlabeled loss)\n",
        "            total_loss = loss + loss_unlabeled  # You can modify this if you want to weight the losses differently\n",
        "            total_loss.backward()\n",
        "            train_loss += total_loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = train_loss / len(labeled_loader.dataset)\n",
        "        # print(f'Epoch {epoch+1}, Average loss: {avg_loss:.4f}')\n",
        "\n",
        "\n",
        "# Extract latent representations\n",
        "def extract_latent_representations(vae, data_loader):\n",
        "    vae.eval()\n",
        "    z_list, y_list = [], []\n",
        "    with torch.no_grad():\n",
        "        for data, labels in data_loader:\n",
        "            data = data.view(data.size(0), -1).to(device)\n",
        "            mu, _ = vae.encode(data)\n",
        "            z_list.append(mu.cpu())\n",
        "            y_list.append(labels.cpu())\n",
        "\n",
        "    return torch.cat(z_list).numpy(), torch.cat(y_list).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8Kx-ML_sreG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def visualize_latent_space(z_train, y_train):\n",
        "    pca = PCA(n_components=2)\n",
        "    z_pca = pca.fit_transform(z_train)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(z_pca[:, 0], z_pca[:, 1], c=y_train, cmap='viridis', alpha=0.5)\n",
        "    plt.colorbar(scatter)\n",
        "    plt.title('PCA of Latent Space')\n",
        "    plt.xlabel('Latent Dimension 1')\n",
        "    plt.ylabel('Latent Dimension 2')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKXAoT7psJBS",
        "outputId": "4fe37157-2760-49e4-c54d-44f1cbcf5ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data sizes for 100 labels:\n",
            "  Labeled data size: 100\n",
            "  Unlabeled data size: 59900\n",
            "  Test data size: 10000\n",
            "  Total training data size: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training VAE with 100 labels: 100%|██████████| 500/500 [00:19<00:00, 25.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with 100 labels: 64.82%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.74      0.72      1000\n",
            "           1       0.98      0.81      0.88      1000\n",
            "           2       0.39      0.48      0.43      1000\n",
            "           3       0.64      0.62      0.63      1000\n",
            "           4       0.49      0.61      0.54      1000\n",
            "           5       0.83      0.41      0.55      1000\n",
            "           6       0.34      0.26      0.29      1000\n",
            "           7       0.62      0.90      0.73      1000\n",
            "           8       0.89      0.80      0.84      1000\n",
            "           9       0.81      0.86      0.83      1000\n",
            "\n",
            "    accuracy                           0.65     10000\n",
            "   macro avg       0.67      0.65      0.65     10000\n",
            "weighted avg       0.67      0.65      0.65     10000\n",
            "\n",
            "VAE weights saved to /content/vae_weights/vae_weights_100_labels.pth\n",
            "\n",
            "Data sizes for 600 labels:\n",
            "  Labeled data size: 600\n",
            "  Unlabeled data size: 59400\n",
            "  Test data size: 10000\n",
            "  Total training data size: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training VAE with 600 labels: 100%|██████████| 500/500 [01:32<00:00,  5.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with 600 labels: 76.32%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.80      0.76      1000\n",
            "           1       0.99      0.90      0.94      1000\n",
            "           2       0.65      0.57      0.61      1000\n",
            "           3       0.71      0.87      0.78      1000\n",
            "           4       0.58      0.61      0.59      1000\n",
            "           5       0.88      0.79      0.83      1000\n",
            "           6       0.46      0.39      0.43      1000\n",
            "           7       0.81      0.90      0.85      1000\n",
            "           8       0.93      0.90      0.91      1000\n",
            "           9       0.87      0.91      0.89      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.76      0.76      0.76     10000\n",
            "\n",
            "VAE weights saved to /content/vae_weights/vae_weights_600_labels.pth\n",
            "\n",
            "Data sizes for 1000 labels:\n",
            "  Labeled data size: 1000\n",
            "  Unlabeled data size: 59000\n",
            "  Test data size: 10000\n",
            "  Total training data size: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training VAE with 1000 labels: 100%|██████████| 500/500 [02:27<00:00,  3.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with 1000 labels: 76.47%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.81      0.76      1000\n",
            "           1       0.99      0.92      0.95      1000\n",
            "           2       0.67      0.55      0.60      1000\n",
            "           3       0.77      0.81      0.79      1000\n",
            "           4       0.56      0.70      0.62      1000\n",
            "           5       0.87      0.79      0.83      1000\n",
            "           6       0.45      0.37      0.41      1000\n",
            "           7       0.81      0.90      0.85      1000\n",
            "           8       0.94      0.90      0.92      1000\n",
            "           9       0.88      0.90      0.89      1000\n",
            "\n",
            "    accuracy                           0.76     10000\n",
            "   macro avg       0.76      0.76      0.76     10000\n",
            "weighted avg       0.76      0.76      0.76     10000\n",
            "\n",
            "VAE weights saved to /content/vae_weights/vae_weights_1000_labels.pth\n",
            "\n",
            "Data sizes for 3000 labels:\n",
            "  Labeled data size: 3000\n",
            "  Unlabeled data size: 57000\n",
            "  Test data size: 10000\n",
            "  Total training data size: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training VAE with 3000 labels: 100%|██████████| 500/500 [07:00<00:00,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy with 3000 labels: 79.90%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.75      0.75      1000\n",
            "           1       0.98      0.94      0.96      1000\n",
            "           2       0.69      0.66      0.67      1000\n",
            "           3       0.79      0.84      0.82      1000\n",
            "           4       0.63      0.72      0.67      1000\n",
            "           5       0.94      0.82      0.88      1000\n",
            "           6       0.52      0.46      0.49      1000\n",
            "           7       0.86      0.91      0.89      1000\n",
            "           8       0.95      0.95      0.95      1000\n",
            "           9       0.86      0.95      0.90      1000\n",
            "\n",
            "    accuracy                           0.80     10000\n",
            "   macro avg       0.80      0.80      0.80     10000\n",
            "weighted avg       0.80      0.80      0.80     10000\n",
            "\n",
            "VAE weights saved to /content/vae_weights/vae_weights_3000_labels.pth\n"
          ]
        }
      ],
      "source": [
        "def run_experiment(num_labels):\n",
        "    print_data_sizes(num_labels)\n",
        "    labeled_indices, unlabeled_indices = split_labeled_data(train_dataset, num_labels=num_labels)\n",
        "\n",
        "    labeled_subset = Subset(train_dataset, labeled_indices)\n",
        "    unlabeled_subset = Subset(train_dataset, unlabeled_indices)\n",
        "\n",
        "    batch_size = 64\n",
        "    labeled_loader = DataLoader(labeled_subset, batch_size=batch_size, shuffle=True)\n",
        "    unlabeled_loader = DataLoader(unlabeled_subset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize and train VAE\n",
        "    vae = VAE().to(device)\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3) #weight decay??\n",
        "\n",
        "    # Initialize the scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.45)  # Halve the LR every 50 epochs\n",
        "\n",
        "    train_vae(vae, labeled_loader, unlabeled_loader, optimizer, num_labels)\n",
        "\n",
        "    # Extract latent representations\n",
        "    z_train, y_train = extract_latent_representations(vae, labeled_loader)\n",
        "    z_test, y_test = extract_latent_representations(vae, test_loader)\n",
        "\n",
        "    # visualize_latent_space(z_train, y_train)\n",
        "\n",
        "    clf = svm.SVC(kernel='rbf', random_state=42) #sigmoid yields bad accuracy\n",
        "    clf.fit(z_train, y_train)\n",
        "\n",
        "    # Test the classifier\n",
        "    y_pred = clf.predict(z_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f'Test Accuracy with {num_labels} labels: {accuracy * 100:.2f}%')\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # Add this function call at the end of your training loop\n",
        "    save_vae_weights(vae, num_labels)\n",
        "\n",
        "\n",
        "# Run experiments for different label sizes\n",
        "for label_size in [100, 600, 1000, 3000]:\n",
        "    run_experiment(label_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNkr99owODBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a0f1f7e-b634-41a1-8515-5771c3056d55"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77a79033-1f48-40d2-9dd8-c433cd238780\", \"vae_weights.zip\", 27140436)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive('vae_weights', 'zip', '/content/vae_weights')\n",
        "files.download('vae_weights.zip')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}